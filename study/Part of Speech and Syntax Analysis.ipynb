{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599564542685",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어간추출(Stemming)\n",
    "- 어간: 단어의 의미를 담고 있는 단어의 핵심 부분\n",
    "- 어간추출은 변화된 단어의 접미사나 어미를 제거하여 같은 의미를 가지는 형태소이 기본형을 찾는 방법\n",
    "- 어간추출법은 단순히 어미를 제거할 뿐이므로 단어의 원형을 정확히 찾아주지는 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Porter Stemmer: ['fli', 'fli', 'fli', 'flew', 'flown']\nLancaster Stemmer: ['fly', 'fli', 'fly', 'flew', 'flown']\n"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "# PorterStemmer, LancasterStemmer 두가지 종류\n",
    "st1 = PorterStemmer()\n",
    "st2 = LancasterStemmer()\n",
    "\n",
    "words = ['fly','flies','flying','flew','flown']\n",
    "\n",
    "print(\"Porter Stemmer:\",[st1.stem(w) for w in words])\n",
    "print(\"Lancaster Stemmer:\",[st2.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원형복원(Lemmatizing)\n",
    "- Lemma: 표제어(기본 사전형 단어)\n",
    "- 원형 복원은 같은 의미를 가지는 여러 단어를 사전형으로 통일하는 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['fly', 'fly', 'fly', 'fly', 'fly']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "#품사(pos)를 동사(v)로 원형 복원\n",
    "[lm.lemmatize(w,pos='v') for w in words] # pos='v': 동사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 형태소 분석(Part of speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\bitcamp\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Emma', 'refused', 'to', 'permit', 'us', 'to', 'obtain', 'the', 'refuse', 'permit']\n\n[('Emma', 'NNP'), ('refused', 'VBD'), ('to', 'TO'), ('permit', 'VB'), ('us', 'PRP'), ('to', 'TO'), ('obtain', 'VB'), ('the', 'DT'), ('refuse', 'NN'), ('permit', 'NN')]\n"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "sentence = \"Emma refused to permit us to obtain the refuse permit\"\n",
    "\n",
    "# 토큰 분리\n",
    "tokens = word_tokenize(sentence)\n",
    "print(tokens)\n",
    "print()\n",
    "\n",
    "# 형태소 분석\n",
    "# token + pos\n",
    "tagged_list = pos_tag(tokens)\n",
    "print(tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package tagsets to\n[nltk_data]     C:\\Users\\bitcamp\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package tagsets is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "NNP: noun, proper, singular\n    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n    Shannon A.K.C. Meltex Liverpool ...\n"
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP') # NNP : 고유명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\n- NNP : 단수 고유명사\\n- VB : 동사\\n- VBP : 동사 현재형\\n- TO : to 전치사\\n- NN  : 명사(단수형 혹은 집합형)\\n- DT : 관형사\\n'"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# 품사부착\n",
    "\"\"\"\n",
    "- NNP : 단수 고유명사\n",
    "- VB : 동사\n",
    "- VBP : 동사 현재형\n",
    "- TO : to 전치사\n",
    "- NN  : 명사(단수형 혹은 집합형)\n",
    "- DT : 관형사\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "VBD: verb, past tense\n    dipped pleaded swiped regummed soaked tidied convened halted registered\n    cushioned exacted snubbed strode aimed adopted belied figgered\n    speculated wore appreciated contemplated ...\n"
    }
   ],
   "source": [
    "# nltk.help.upenn_tagset-자세한 설명\n",
    "nltk.help.upenn_tagset('VBD') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "DT: determiner\n    all an another any both del each either every half la many much nary\n    neither no some such that the them these this those\n"
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('DT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['refuse', 'permit']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 품사가 NN인 것만 추출\n",
    "nouns_list = [t[0] for t in tagged_list if t[1]=='NN']\n",
    "nouns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Emma',\n 'refused',\n 'to',\n 'permit',\n 'us',\n 'to',\n 'obtain',\n 'the',\n 'refuse',\n 'permit']"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from nltk.tag import untag\n",
    "\n",
    "# 품사 태그 제거\n",
    "untag(tagged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Emma/NNP',\n 'refused/VBD',\n 'to/TO',\n 'permit/VB',\n 'us/PRP',\n 'to/TO',\n 'obtain/VB',\n 'the/DT',\n 'refuse/NN',\n 'permit/NN']"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# 단어와 품사를 합쳐서 하나의 토큰으로 변환\n",
    "word_tag = [\"/\".join(p) for p in tagged_list]\n",
    "word_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구문분석(Syntax Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NP: {<DT>? <JJ>* <NN>*} # NP\n",
    "# P: {<IN>}           # Preposition\n",
    "# V: {<V.*>}          # Verb\n",
    "# PP: {<P> <NP>}      # PP -> P NP\n",
    "# VP: {<V> <NP|PP>*}  # VP -> V (NP|PP)*\n",
    "\n",
    "### {<N.*>}     - 명사(N으로 시작)인 모든 경우 \n",
    "### {<P.*>}     - 대명사(P로 시작)인 모든 경우\n",
    "### {<DT><JJR>}  - DT와 JJR이 붙어 있는 경우\n",
    "### {<DT><J.*>}  - DT와 J로 시작하는 단어가 붙어 있는 경우 \n",
    "### {<DT><JJ>?<NN>} - <DT>와 <NN>사이에 <JJ>가 있든 없든\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP the/DT little/JJ yellow/JJ dog/NN)\n  barked/VBD\n  at/IN\n  (NP the/DT cat/NN))\n"
    }
   ],
   "source": [
    "# 품사 정보가 있는 문장 설정\n",
    "# the little yellow dog barked at the cat\n",
    "sentence = [(\"the\",\"DT\"),(\"little\",\"JJ\"),(\"yellow\",\"JJ\"),(\"dog\",\"NN\"),(\"barked\",\"VBD\"),(\"at\",\"IN\"),(\"the\",\"DT\"),(\"cat\",\"NN\")]\n",
    "\n",
    "# 문법 정의\n",
    "grammer = \"NP:{<DT>?<JJ>*<NN>}\"\n",
    "# NP : Noun phrase\n",
    "\n",
    "# 정규표현식 파서\n",
    "cp = nltk.RegexpParser(grammer)\n",
    "result = cp.parse(sentence)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)\n",
    "\n",
    "# 결과를 트리로 표시\n",
    "result.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글형태소 분석\n",
    "- KoNLPy는 자바로 구현되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['자연어', '자연어처리', '처리', '컴퓨터', '인간', '언어', '인공', '인공지능', '지능']\n['자연어', '처리', '는', '컴퓨터', '가', '인간', '의', '언어', '를', '처리', '하', '도록', '하', '는', '인공지능', '이', 'ㅂ니다', '.']\n[('자연어', 'NNG'), ('처리', 'NNG'), ('는', 'JX'), ('컴퓨터', 'NNG'), ('가', 'JKS'), ('인간', 'NNG'), ('의', 'JKG'), ('언어', 'NNG'), ('를', 'JKO'), ('처리', 'NNG'), ('하', 'XSV'), ('도록', 'ECD'), ('하', 'VV'), ('는', 'ETD'), ('인공지능', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n"
    }
   ],
   "source": [
    "sentence = \"자연어처리는 컴퓨터가 인간의 언어를 처리하도록 하는 인공지능입니다.\"\n",
    "\n",
    "# 꼬꼬마 형태소분석기 사용\n",
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "print(kkma.nouns(sentence)) # 명사\n",
    "print(kkma.morphs(sentence))# 형태소\n",
    "print(kkma.pos(sentence))   # 형태소와 품사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['자연어', '처리', '컴퓨터', '인간', '언어', '처리', '인공지능']\n['자연어', '처리', '는', '컴퓨터', '가', '인간', '의', '언어', '를', '처리', '하', '도록', '하', '는', '인공지능', '이', 'ㅂ니다', '.']\n[('자연어', 'NNP'), ('처리', 'NNP'), ('는', 'JX'), ('컴퓨터', 'NNG'), ('가', 'JKS'), ('인간', 'NNG'), ('의', 'JKG'), ('언어', 'NNG'), ('를', 'JKO'), ('처리', 'NNG'), ('하', 'XSV'), ('도록', 'EC'), ('하', 'VV'), ('는', 'ETM'), ('인공지능', 'NNP'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF')]\n"
    }
   ],
   "source": [
    "# 코모란 형태소 분석기 사용\n",
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "\n",
    "print(komoran.nouns(sentence))\n",
    "print(komoran.morphs(sentence))\n",
    "print(komoran.pos(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy 말뭉치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "대한민국헌법\n\n유구한 역사와 전통에 빛나는 우리 대한국민은 3·1운동으로 건립된 대한민국임시정부의 법통과 불의에 항거한 4·19민주이념을 계승하고, 조국의 민주개혁과 평화적 통일의 사명에 입각하여 정의·인도와 동포애로써 민족의 단결을 공고히 하고, 모든 사회적 폐습과 불의를 타파하며, 자율과 조화를 바탕으로 자유민주적 기본질서를 더욱 확고히 하여 정치·경제·사회·문화의 모든 영역에 있어서 각인의 기회를 균등히 하고, 능력을 최고도로 발휘하게 하며, 자유와 권리에 따르는 책임과 의무를 완수하게 하여, 안으로는 국민생활의 균등한 향상을 기하고 밖으로는 항구적인 세계평화와 인류공영에 이바지함으로써 우리들과 우리들의 자손의 안전과 자유와 행복을 영원히 확보할 것을 다짐하면서 1948년 7월 12일에 제정되고 8차에 걸쳐 개정된 헌법을 이제 국회의 의결을 거쳐 국민투표에 의하여 개정한다.\n\n       제1장 총강\n  제1조 ① 대한민국은 민주공화국이다.\n②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n  제2조 ① 대한민국의 국민이 되는 요건은 법률로 정한다.\n②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n  제3조 대한민국의 영토는 한반도와 그 부속도서로 한다.\n  제4조 대한민국은 통일을 지향하며, 자유민주적 기본질서에 입각한 평화적 통일 정책을 수립하고 이를 추진한다.\n  제5조 ① 대한민국은 국제평화의 유지에 노력하고 침략적 전쟁을 부인한다.\n②국군은 국가의 안전보장과 국토방위의 신성한 의무를 수행함을 사명으로 하며, 그 정치적 중립성은 준수된다.\n  제6조 ① 헌법에 의하여 체결·공포된 조약과 일반적으로 승인된 국제법규는 국내법과 같은 효력을 가진다.\n②외국인은 국제법과 조약이 정하는 바에 의하여 그 지위가 보장된다.\n  제7조 ① 공무원은 국민전체에 대한 봉사자이며, 국민에 대하여 책임을 진다.\n②공무원의 신분과 정치적 중립성은 법률이 정하는 바에 의하여 보장된다.\n  제8조 ① 정당의 설립은 자유이며, 복수정당제\n"
    }
   ],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "\n",
    "# 한국 법률 말뭉치\n",
    "text = kolaw.open('constitution.txt').read()\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "지방공무원법 일부개정법률안\n\n(정의화의원 대표발의 )\n\n 의 안\n 번 호\n\n9890\n\n발의연월일 : 2010.  11.  12.  \n\n발  의  자 : 정의화․이명수․김을동 \n\n이사철․여상규․안규백\n\n황영철․박영아․김정훈\n\n김학송 의원(10인)\n\n제안이유 및 주요내용\n\n  초등학교 저학년의 경우에도 부모의 따뜻한 사랑과 보살핌이 필요\n\n한 나이이나, 현재 공무원이 자녀를 양육하기 위하여 육아휴직을 할 \n\n수 있는 자녀의 나이는 만 6세 이하로 되어 있어 초등학교 저학년인 \n\n자녀를 돌보기 위해서는 해당 부모님은 일자리를 그만 두어야\n"
    }
   ],
   "source": [
    "from konlpy.corpus import kobill\n",
    "\n",
    "# 대한민국 국회 의안 말뭉치\n",
    "text = kobill.open('1809890.txt').read()\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 구문분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  만/Noun\n  6/Number\n  세/Noun\n  이하/Noun\n  의/Josa\n  초등학교/Noun\n  취학/Noun\n  전/Noun\n  자녀/Noun\n  를/Josa\n  양육/Noun\n  (VP 하기/Verb)\n  위/Noun\n  (VP 해서는/Verb))\n"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import nltk\n",
    "\n",
    "# 형태소 분석\n",
    "sentence = \"만 6세 이하의 초등학교 취학 전 자녀를 양육하기 위해서는\"\n",
    "words = Okt().pos(sentence)\n",
    "\n",
    "# words\n",
    "# 문법정의\n",
    "grammar = \"\"\"\n",
    "NP:{<n.*>*<Suffix>?} # Noun phrase\n",
    "VP:{<V.*>*}          # Verb phrase\n",
    "AP:{<A.*>*}          # Adjective phrase\n",
    "\"\"\"\n",
    "\n",
    "# 정규표현식 파서\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "\n",
    "# 결과 출력\n",
    "print(chunks)\n",
    "\n",
    "# 결과를 트리로 표시\n",
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}